
\documentclass{uniquecv}

\usepackage{fontawesome}

% ----------------------------------------------------------------------------- %

\begin{document}

\name{Run Luo}

\medskip

\basicinfo{
  \faPhone ~ (+86) 191-7925-8153
  \textperiodcentered\
  \faEnvelope ~ lr\_8823@hust.edu.cn
  \textperiodcentered\
  \faGithub ~ github.com/run-qiao
}

% ----------------------------------------------------------------------------- %

\section{Education Background}
\dateditem{\textbf{Huazhong University of Science and Technology} \quad Civil Engineering \quad undergraduate}{2019 -- 2020}
\dateditem{\textbf{Huazhong University of Science and Technology} \quad Software Engineering \quad undergraduate}{2020 --  present}
Rank：15\%(13|84) \quad GPA 3.9 \quad English：CET6


% ----------------------------------------------------------------------------- %

\section{Skills}
\smallskip
C/C++、Python、Java、Data Structure And Algorithm、Linux、Spark、Pytorch、Tensorflow、High Performance Computing Cluster Optimization And Parellel Computing


% ----------------------------------------------------------------------------- %

\section{Awards}
\datedaward{The Second}{\textbf{ASC2022}}{2022.3}
\datedaward{H}{MCM}{2022.5}
\datedaward{The Second of Provincial}{CMC}{2021.11}
\datedaward{\small{The Third}}{Mobile Application Development Competition} {2021.12}
\medskip

% ----------------------------------------------------------------------------- %

\section{Project Experience}

% ---
\datedproject{ASC2022}{Competition}{2022.1 -- 2022.3}
\textit{GPT2、Cluster Training Optimization、Parellel Computing}
\vspace{0.4ex}

Optimizing the training and convergency speed of large language model like GPT2 in multi machine nodes with multi GPU by using different acceleration training and convergence strategies
\begin{itemize}
  \item Different parallel strategies, convergence strategies and parallel frameworks are combined to make the convergence time and training time as short as possible. Making 4.7B large language model GPT2 converges in about half an hour in 4 machine nodes with 8 V100
\end{itemize}
% ---
\datedproject{SOT}{Research}{2022.3 -- 2022.5}
\textit{Pytorch、SOT，\textbf{MM2022 Under Review}}
\vspace{0.4ex}

On the basis of Stark, it's proposed to use similar templates that have appeared in the high-quality template library to improve the target tracking ability of the tracker in the current frame, which can well improve the tracking ability of the tracker in the scene of severe deformation of the target appearance, and add structures such as alignment and template verification. \textbf{The test ranking result on trackingnet is second only to mixformer}
% ---
\datedproject{MOT}{Research}{2021.12 -- 2022.3}
\textit{Pytorch、Attack and Defence to MOT}
\vspace{0.4ex}

Adversarial Training enhances the robustness of FairMOT, ByteTrack and other post-processing trackers, and refines the post-processing method to imporve the multiple object tracking and defense performance in multi-target motion secenario
% ---
\datedproject{Style Transfer Album}{Competition}{2021.10 -- 2021.12}
\textit{Android、Pytorch,Image Style Transfer，Ncnn Deployment}
\vspace{0.4ex}

A cartoon style conversion album developed by Android can record and share your daily life.I rebuild the transfer style network with Pytorch and then deploy it in NCNN 
framework 
\begin{itemize}
  \item The onnx operator optimizes and compresses network parameters, reduces power consumption, accelerates the inference on mobile phones and improves the response speed. At the same time, the matting network is integrated to remove the background matting, which is convenient for adding background, style conversion and other secondary processing.
\end{itemize}
% ----------------------------------------------------------------------------- %
\section{Extracurricular}
\dateditem{\textbf{Member of Unique Studio Club AI Group}}{2021.4 -- present}
\dateditem{\textbf{Leader of AI group ,Science and Technology Innovation Team, School of Software Engineering}}{2021.8 -- present}
\dateditem{\textbf{Member of Hexagon Supercomputing Team}}{2021.12 -- present}
\end{document}
